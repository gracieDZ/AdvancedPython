{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c46425a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Scientific Python and Data Manipulation\n",
    "## Advanced Python for Life Sciences @ Physalia courses (Summer 2025)\n",
    "### Marco Chierici, Fondazione Bruno Kessler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f70131-cd5e-42eb-9669-28dcd2ab3f46",
   "metadata": {},
   "source": [
    "# NumPy\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Suppose you have to work with matrices and perform a matrix multiplication. You could create matrices in pure Python by using nested lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97514c2d-f532-4d21-b69a-57f77ee38b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c02e28-e9d3-4162-bc15-e3dfcf3a8f67",
   "metadata": {},
   "source": [
    "This creates a 3x3 matrix that should look like this:\n",
    "\n",
    "```\n",
    "1 2 3\n",
    "4 5 6\n",
    "7 8 9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb453bb0-95b7-4a0b-ad66-833c062bf862",
   "metadata": {},
   "source": [
    "And then you can access the individual items by their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65013b68-2f38-4ddd-be4a-56ae8fcf69bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0644c1-27d7-4d2c-95b3-ecf1d6a75838",
   "metadata": {},
   "source": [
    "How could you multiply each item by 2? For example, you can use a nested `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef61c9a-dbbd-4699-b9fc-9cd89da9919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in matrix:\n",
    "    for i in range(len(row)):\n",
    "        row[i] = row[i] * 2\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77187139-972e-474e-a0e8-0940dc946261",
   "metadata": {},
   "source": [
    "The output is correct; the problem is that all of this is done in pure Python and you thus need to reimplement every operation you need to use!\n",
    "\n",
    "**NumPy** brings N-dimensional arrays and linear algebra routines to Python.\n",
    "\n",
    "More info and full documentation: https://numpy.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcf75c-4047-4b69-af00-afceaeb012a7",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759c47d-b617-4c25-8dec-68523f1d66fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# canonical import\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd517a18-f622-4d67-9263-e29b2da18251",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# a one-dimensional array\n",
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51396754-211d-4282-92a1-b7e54765f7ee",
   "metadata": {},
   "source": [
    "You can index a Numpy array like you would to with a nested list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2318a-352d-4f89-84b0-4044de46c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f911d2-0b1a-4a44-ae29-9bde091c0248",
   "metadata": {},
   "source": [
    "Or with the numpy-specific slicing syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8bb99-3da5-49b9-8818-0d2367bc9453",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9b88e-fa17-4fe5-95f2-af466986a7e9",
   "metadata": {},
   "source": [
    "Arrays contain items of a single type: this is one major difference with respect to lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc7666-2d58-4bdb-bc4a-7dea5cf28c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1, 2, 3], [\"a\", \"b\", \"c\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee718577-29a9-4d23-b187-30f34c8f0fa0",
   "metadata": {},
   "source": [
    "You can create three-dimensional arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cfac4-69f2-42eb-b192-8685c196575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([\n",
    "    [[1, 2, 3], [4, 5, 6]], \n",
    "    [[7, 8, 9], [10, 11, 12]],\n",
    "    [[13, 14, 15], [16, 17, 18]]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99353dd-4f5e-4e07-ba08-4fb18f191ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[0, 1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f769ee-e271-470e-8dbb-ec8f14d3b1a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d10ed-9558-4fd8-9da9-6bd0e801581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "matrix * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97157fb2-007f-47d6-a686-8e626273bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_matrix = np.array([[5, 4, 3], [7, 6, 5], [9, 8, 7]])\n",
    "second_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4cf1d8-da33-4cfc-82ed-b0117337674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_matrix - matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78671f9f-6f37-46d2-b7fb-dd837f4530af",
   "metadata": {},
   "source": [
    "Mind the difference between core Python and Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a9606-2333-48ed-adae-110bcecaf0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regular or \"core\" Python\n",
    "print([1, 2, 4] + [3, 5, 6])\n",
    "\n",
    "# use numpy to add\n",
    "np.array([[1, 2, 4]]) + np.array([3, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9debb1c1-b860-4754-98e8-88617985a940",
   "metadata": {},
   "source": [
    "All arithmetic operators + - * / operate *element by element*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda4151-4949-4e1f-9ba8-8e58d07def89",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n",
    "matrix * matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af06f9f-bd64-469f-a624-6673ea4113fd",
   "metadata": {},
   "source": [
    "Matrix product is computed with the `@` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e418b70-79f9-4e4a-a272-504616535a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix @ matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a157b2-3369-4a3b-bc89-aa73cfcd612c",
   "metadata": {},
   "source": [
    "Other common array operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3be2cf-305d-4bb9-9606-02e858adb9ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde8006-7820-491b-9322-8ad1c1687f0f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# dimension or shape\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e7210-885e-48ca-8436-3ccdf2e46aa4",
   "metadata": {},
   "source": [
    "Note that `.shape` is an *attribute* of `matrix` and not a function or method: a common error is to call it like `matrix.shape()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d0d2d-db0c-4b1f-a694-32bfca9e8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e0f16-9f9d-4968-ad8c-27dc779def9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f66136-7afa-446d-90a7-ea26d12cd759",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e37f49-38b1-483b-9eda-08d5c8267686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent\n",
    "matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0946ea-0453-4253-87da-a0b366c45121",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb46be-b635-4d7c-a6a6-690ada204fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent\n",
    "matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91db5e-0310-4470-a294-ecf73078ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(matrix))\n",
    "#or\n",
    "matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259e6b5-bde4-43c4-a07c-35ea90bf3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.mean()  # or np.mean(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4548d46-d6ae-4621-9d64-ca3c6a510d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(matrix)  # element by element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a10238-a373-4ed1-8e50-42eda44888f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(matrix)  # element by element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda01f46-a500-4045-97fc-e963018a5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log2(matrix)  # element by element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e4eac-8e4b-4e4f-8808-cd82c51879ab",
   "metadata": {},
   "source": [
    "## Ranges of values\n",
    "\n",
    "`np.arange()` is the Numpy equivalent to `range()` and returns a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2787cc2-a100-40d5-aea7-be13fdd9bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efd804-7d1e-4632-a33f-02119d46b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4802dd4-c89b-473e-83ae-8c7955ad03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10, 20, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4c066-6ff7-4eba-a310-cd9f324d3dde",
   "metadata": {},
   "source": [
    "### Shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d171328-619e-4729-89df-1b0a58205a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "print(A)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb9853-815d-4efb-a72d-20405c0a5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.reshape(9, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58f5c3-f07e-403d-8f26-8f2b9a3b0cf7",
   "metadata": {},
   "source": [
    "Note that you can only reshape an array if the total size of the reshaped array matches the original size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3b2f0-05be-4fd7-ae63-913340764130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will raise an error:\n",
    "# A.reshape(2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd8635-f057-462c-b943-b2efd56c237c",
   "metadata": {},
   "source": [
    "If one of the parameters of `reshape()` is -1, then Numpy will determine that value depending on the other parameter and the total array size.\n",
    "\n",
    "For example, `arr.reshape(3, -1)` means \"reshape arr to three rows and as many columns it takes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238db3f2-97cc-4d32-ba41-c0f7c3619a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dad427-9a4a-41d2-bfa0-bfca4b6dd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.reshape(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21b0d1-dd26-4762-a952-cd645169b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15952410-8231-4bb9-ab19-26e9f98a016b",
   "metadata": {},
   "source": [
    "## Randomness\n",
    "\n",
    "The `np.random` module allows you to perform random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0284b-5acf-4672-b3a8-d76295bf835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed before generating random data\n",
    "np.random.seed(11)\n",
    "# draw samples from a normal distribution with 0 mean and 1 sd\n",
    "# and put the output in a 3x3 array\n",
    "np.random.normal(size=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ff85f-497e-4756-8048-d21d06c607cb",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- **[Numpy cheat sheet](https://images.datacamp.com/image/upload/v1676302459/Marketing/Blog/Numpy_Cheat_Sheet.pdf)** (also in the `resources` folder)\n",
    "- [Numpy tutorials and books](https://numpy.org/learn/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1f3b0-1f1b-4d90-8ef0-15a65d53e18d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Scipy\n",
    "\n",
    "- Scientific Python\n",
    "- Built on top of NumPy\n",
    "- Provides more complex mathematic, statistical, and scientific data analysis functions\n",
    "  - Still, NumPy contains some linear algebra functions and Fourier transforms, even though these more properly belong in SciPy\n",
    "\n",
    "More info and full documentation: https://scipy.org\n",
    "\n",
    "Some particularly useful `scipy` sub-packages include:\n",
    "\n",
    "- `scipy.stats`\n",
    "  - randomness\n",
    "  - statistical functions and tests\n",
    "- `scipy.integrate`\n",
    "  - numerical integration\n",
    " \n",
    "Other useful sub-packages include `scipy.linalg` for linear algebra and `scipy.sparse` for sparse matrix problems (e.g. single-cell RNA-seq).\n",
    "\n",
    "We'll briefly touch here how to do simple statistical testing with `scipy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7109083-34cb-4e27-86d9-4ff4dcf5e52c",
   "metadata": {},
   "source": [
    "## Statistical testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf5b7e-7553-478a-a16f-a06216f71d85",
   "metadata": {},
   "source": [
    "`stats` contains functions for statistical hypothesis testing. For example, let's conduct a *paired t-test* to compare two sets of related measurements, such as the same biological parameter measured before and after a treatment in the same subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3063120-f8f2-4cf7-904b-2b808e900476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# set a seed before generating random data\n",
    "np.random.seed(12345)\n",
    "# assume these are two sets of biological measurements\n",
    "data_before = np.random.normal(loc=50, scale=10, size=100)  # before treatment\n",
    "# we manually shift data_before to simulate the effect of a treatment\n",
    "data_after = data_before + np.random.normal(loc=5, scale=5, size=100)  # after treatment\n",
    "\n",
    "# paired t-test\n",
    "t_statistic, p_value = stats.ttest_rel(data_before, data_after)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da6fee-a8c0-4b89-bccf-13b264e3624f",
   "metadata": {},
   "source": [
    "The p-value is way less than the usual significance threshold of 0.05, so we reject the null hypothesis that there is no difference between the two sets of measurements.\n",
    "\n",
    "The *nonparametric version* of the paired t-test is the Wilcoxon signed-rank test: let's conduct this kind of test on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c369cd0-376d-4eff-9699-e5fe5c0e3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(data_before, data_after)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24f8c0-8bc7-45db-9b46-6d5f134010df",
   "metadata": {},
   "source": [
    "Again, this p-value indicates a statistically significant difference in this example data.\n",
    "\n",
    "Wilcoxon signed-rank is especially used instead of the paired t-test when the data are not normally distributed, thus they do not meet the assumptions of a t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f45c6a-2535-4420-9f22-9d99e7d5d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed before generating random data\n",
    "np.random.seed(999)\n",
    "# non-normally distributed data from a log-normal distribution\n",
    "data_before_non_normal = np.random.lognormal(mean=1.5, sigma=0.4, size=30)\n",
    "data_after_non_normal = data_before_non_normal * np.random.lognormal(mean=0.1, sigma=0.4, size=30)\n",
    "\n",
    "# Performing the Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(data_before_non_normal, data_after_non_normal)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d44e03-f4ba-4fe6-a1df-fc29c1d7bb7c",
   "metadata": {},
   "source": [
    "If, instead, you want to assess statistical significance of *independent samples* (i.e., one group of patients vs. another group of different patients), you can use a t-test (`stats.ttest_ind`) or a Mann-Whitney U test (`stats.mannwhitneyu`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972a1e8-f1eb-42c5-8518-f66a85fcd9e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(999)\n",
    "\n",
    "# two independent non-normal samples from log-normal dists\n",
    "group_a = np.random.lognormal(mean=1.5, sigma=0.4, size=30)\n",
    "group_b = np.random.lognormal(mean=1.2, sigma=0.5, size=30)\n",
    "\n",
    "# perform the Mann–Whitney U test\n",
    "statistic, p_value = stats.mannwhitneyu(group_a, group_b, alternative='two-sided')\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e4260-887f-4552-aaea-5ce58f166e70",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Adjust for multiple testing\n",
    "\n",
    "When you conduct many tests, such as for differential gene expression analysis, you need to correct the p-values for multiple testing (for example, with the Benjamini-Hochberg procedure).\n",
    "\n",
    "p-value correction is implemented in the 3rd-party Python library [statsmodels](https://www.statsmodels.org/stable/index.html)\n",
    "\n",
    "`!conda install -y -c conda-forge statsmodels`\n",
    "\n",
    "In particular, p-value correction is in the function `statsmodels.stats.multitest.multipletests(pvals, method)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c90f1-a2ba-49b7-9239-c4a1f162a352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32ee4a-29dd-476a-993d-e6ae66ea6cbc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedd1dd-d49e-4e1b-a991-5223a9cd4f80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(999)\n",
    "\n",
    "# 10 independent Mann–Whitney U tests (we simulate testing on 10 genes)\n",
    "p_vals = []\n",
    "for i in range(10):\n",
    "    group_a = np.random.lognormal(mean=1.5, sigma=0.4, size=30)\n",
    "    group_b = np.random.lognormal(mean=1.2, sigma=0.5, size=30)\n",
    "\n",
    "    _, p = stats.mannwhitneyu(group_a, group_b, alternative=\"two-sided\")\n",
    "    p_vals.append(p)\n",
    "\n",
    "np.array(p_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58261af7-8b74-4ef7-a009-651784057912",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p-value adjustment\n",
    "multipletests(np.array(p_vals), alpha=0.05, method=\"fdr_bh\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d2063-b161-47cf-9f72-ce2e1203481f",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- **[Scipy cheat sheet](https://images.datacamp.com/image/upload/v1676303474/Marketing/Blog/SciPy_Cheat_Sheet.pdf)** (also in the `resources` folder)\n",
    "- [Scipy documentation](https://docs.scipy.org/doc/scipy/)\n",
    "- If you work a lot with statistical models and statistical tests, check out the [statsmodels](https://www.statsmodels.org/stable/index.html) library!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14871d4-6e74-4ac4-b8a4-73e4a1de13cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Pandas\n",
    "\n",
    "- \"The\" Python library for **data preprocessing and analysis**\n",
    "- Built **on top of Numpy**\n",
    "- Extremely versatile for manipulating datasets, mostly tabular data\n",
    "- Think of Pandas as the **evolution of spreadsheets**, with more capabilities for coding, and queries on relational data such as joins and group-by\n",
    "- Bonus: can be used for high quality **plots**\n",
    "- Most important structure: the **Data Frame** (R users: yes, that one!)\n",
    "- Trivia: stands for **Pan**el **Da**ta **S**ystem\n",
    "\n",
    "More info and full documentation: https://pandas.pydata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de903f6-57df-40a5-a019-bf890b278418",
   "metadata": {},
   "source": [
    "A peek of what you can do with Pandas' toolbox:\n",
    "\n",
    "- managing data and tables\n",
    "  - selection\n",
    "  - grouping\n",
    "  - pivoting\n",
    "- managing missing data\n",
    "- preprocessing and data wrangling\n",
    "- file I/O\n",
    "- statistics on data\n",
    "\n",
    "## Resources\n",
    "We won't cover everything Pandas can do, so keep this **[cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)** handy! (it's also in the `resources` folder)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d40e9-9e76-4bf5-8a26-f2ec45e14a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# canonical import\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b919d-2484-47c7-92ec-9f0703221c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll also need this to improve dealing with files, folders, and paths\n",
    "from pathlib import Path\n",
    "DATADIR = Path(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f91f9-9335-4c17-8b5e-a2039db85da4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Series\n",
    "\n",
    "A Pandas Series is a 1D container, similar to the Python list. With respect to lists, however, a Series can only hold items of the same `dtype`.\n",
    "\n",
    "- 1D labeled array: in essence, a column\n",
    "- Homogenous data type\n",
    "- Size - immutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf088d7-aca2-4bac-a96f-be906c401fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series using lists\n",
    "# note: index defaults to 0, 1, 2, ... if not given.\n",
    "genes = pd.Series([0.2, 1.4, 4, 5], index=[\"GeneA\", \"GeneB\", \"GeneC\", \"GeneD\"])\n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd1843-edf1-432b-8df3-6db4251d74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e07b8-b10b-4d6d-927f-3a2dd215405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows and columns\n",
    "# (shape is an attribute)\n",
    "genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0062a4f-bb31-4db1-9d15-9ab288dba5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index values (another attribute)\n",
    "genes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8dcf3d-4862-4d28-95e1-f20514d8584e",
   "metadata": {},
   "source": [
    "Note that index has their own type `Index` - it is not a Python list (even though it looks like a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e0419d-30ae-499f-87ae-a026d4a134dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the type\n",
    "genes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e35999-6bc3-43dd-9da6-655a485beece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more info\n",
    "genes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52185745-c370-4355-891e-f09936607d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series from a dictionary\n",
    "genes2 = pd.Series(\n",
    "    {\"GeneA\": 0.2, \"GeneB\": 1.4, \"GeneC\": 4.0, \"GeneD\": 5, \"GeneE\": np.nan}\n",
    ")\n",
    "print(genes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12796b-8d79-471e-8a56-9c63902e274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give index column a name\n",
    "genes2.rename_axis(\"Gene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23fe3c5-f4db-4a5a-92b2-f3aba46d643a",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "Checking for missing values is one of the main steps in your data preprocessing workflow. If you find missing data, you basically have three options:\n",
    "\n",
    "- keep it (easiest; depends on whether your downstream analysis methods can deal with NANs)\n",
    "- remove it (easy; potential loss of data; limits trained models for future data)\n",
    "- replace it (hardest, somewhat arbitrary; potential to save a lot of data for model training; potential to lead to false conclusions)\n",
    "\n",
    "Keep in mind that no approach applies to all circumstances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7225481-67dc-47d3-887b-b1ace277b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NA values\n",
    "print(genes2.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f0684-417f-4223-9abd-113abd18994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA values\n",
    "genes2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789bbc7a-8e7a-48b4-b81c-45317126ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1461e1b2-41d9-4945-972e-d45d1a1cf4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA values inplace\n",
    "genes3 = genes2.copy()\n",
    "genes3.dropna(inplace=True)\n",
    "genes3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bdaedd-e7e1-441d-9823-b7accc82ccea",
   "metadata": {},
   "source": [
    "**Note:** many Pandas functions and methods that alter dataframes support the parameter `inplace`, which by default is always `False`. In this case, the function returns `None` and the input dataframe is overwritten. In general, *you should avoid using `inplace=True`*. Moreover, this parameter could be deprecated in a future Pandas version (see [here](https://github.com/pandas-dev/pandas/issues/16529))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f3251-d460-4eca-9dac-483a0274a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA values with a custom value\n",
    "genes2.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f11be4-cf74-40b0-b3cb-97baaf577481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA values with a custom value\n",
    "genes2.fillna(value=genes2.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ac0f6-24b9-4944-bf5e-480ff4ffc215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA values propagating the last valid observation to next valid\n",
    "genes2.ffill()  # use this instead of genes2.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f811fd2a-9291-4af7-a636-5ba966b3f662",
   "metadata": {},
   "source": [
    "So what to do with missing values? Here are some rules of thumb.\n",
    "\n",
    "- You should **drop values** when a lot of data is missing;\n",
    "- You should **fill with the same value** if you know that NaN is just a placeholder (e.g., for 0);\n",
    "- You should **fill with interpolated or estimated value** if there is a reasonable assumption to do that!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e803c-87a0-4b9c-8d42-47db9040bf20",
   "metadata": {},
   "source": [
    "### Selecting/Filtering Values in a series\n",
    "\n",
    "1. What is the value of GeneC? There are multiple options to access GeneC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c198a-7cbb-4ba5-9547-3a98d7258089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot notation\n",
    "genes.GeneC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd74a1-3590-4615-bab5-ada80a1ba37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by row name\n",
    "genes[\"GeneC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b819adb-648c-4266-9051-46222fd041df",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes.loc[\"GeneC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088cb8e-162d-409a-9124-4becfb2cac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by row index\n",
    "genes.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61e556-044d-4e01-ba2f-76f11d3585ca",
   "metadata": {},
   "source": [
    "2. What is the value of GeneC and GeneD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933a12f-f040-4aac-a641-8978f3151009",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes[[\"GeneC\", \"GeneD\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a263a-5cb6-49e1-a4d7-79db490e6b28",
   "metadata": {},
   "source": [
    "3. What genes are expressed with a value of at least 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2116d4a4-d7fd-4cb6-b4c1-5e209183e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes[genes > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a668a3-084b-483c-b9f5-fdaf7e845c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with multiple conditions\n",
    "genes[(genes > 3) | (genes < 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180406c-753d-486f-bd08-c993cfb65df4",
   "metadata": {},
   "source": [
    "- Multiple conditions can be combined using the symbols `|` (meaning \"or\") and `&` (meaning \"and\").\n",
    "  - Be sure to wrap each condition around parentheses `( )`\n",
    "  - Don't use Python's `or`, `and` Boolean operators\n",
    "- In Pandas, the Boolean negation operator is the tilde `~`.\n",
    "- Use the `.isin()` method to select data whose value \"is in\" a list of values (mostly used with categorical variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c5420-bc6c-4c5b-8463-37cd7e12031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes.isin([5.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c902295-bcdb-4f77-94cf-fa2cfc50decf",
   "metadata": {},
   "source": [
    "4. What is the mean expression of the whole data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f74ba-3b4a-4eb6-89e4-168063ec46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa65b46-c0f9-41bc-bbdd-3dee567098a4",
   "metadata": {},
   "source": [
    "5. What is the largest value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6ae6b-9be5-495a-948e-904b6550187d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "genes.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b38067-99a9-4fcc-bc70-2647fdac01ae",
   "metadata": {},
   "source": [
    "6. What gene has the largest value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e634dc-00a5-4769-974e-16e57afd021b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "genes[genes == genes.max()].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fd358-21ca-4bc2-9d23-1b50b177b2ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alternative\n",
    "genes.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d878913-f596-4a91-a598-db4cffe85989",
   "metadata": {},
   "source": [
    "### Sorting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a25b20-3d77-453c-ab94-9d33b8ffa9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort from highest to lowest\n",
    "# note: default is increasing order! check ?genes.sort_values\n",
    "genes.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2f18e-5527-4e32-bcf3-0f0fbdad86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "?genes.sort_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf20360-1c81-4a88-9d20-3e6d3ec2c4fa",
   "metadata": {},
   "source": [
    "### Replacing values\n",
    "\n",
    "If you have a categorical (factor) Series, it may be convenient to rename its levels. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62151781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dummy pandas series with a categorical variable (levels: \"M\", \"F\")\n",
    "sex = pd.Series([\"M\", \"F\", \"M\", \"F\", \"M\", \"F\"], name=\"sex\")\n",
    "sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"M\" and \"F\" with \"Male\" and \"Female\"\n",
    "sex.replace(to_replace=[\"M\", \"F\"], value=[\"Male\", \"Female\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a643b-4394-47fa-90fe-623aada6b36b",
   "metadata": {},
   "source": [
    "An alternative to `.replace()` is the method `.map()`, which accepts a Python dictionary like `{old_value1: new_value1, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15ee40-fbdc-40e9-91f8-54f717367716",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex.map({\"M\": \"Male\", \"F\": \"Female\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac41aaa-2889-44cf-b448-e2fdb50bd06f",
   "metadata": {},
   "source": [
    "`.map()` is more flexible than `.replace()` and gracefully deals with `dtype` changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c13f8-1ad8-43f3-8a60-423534ee3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex.replace(to_replace=[\"M\", \"F\"], value=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2e038-8f85-4c6b-b1da-eb7b01578323",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex.map({\"M\": 0, \"F\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec80a4-f220-4e7f-8e85-28f94ba559cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex.isin(['F'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b530e609-3712-4bd7-a4a2-d6979c88f593",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4371cacf-c6a5-4102-b792-751c8ab19533",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "A Pandas DataFrame can be thought of as a collection (or a dictionary) of Series objects. The keys in this dictionary are the column names and the values are the Series.\n",
    "\n",
    "- 2D labeled table made up of a collection of Series\n",
    "- Potentially heterogeneous data types\n",
    "- Size - mutable\n",
    "\n",
    "To create a DataFrame from scratch, there are multiple possibilities: we decide to create a dictionary first, then convert it to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d0f04-544a-4d94-8021-e193aba9cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"EnsemblID\": [\n",
    "        \"ENSG00000223972\",\n",
    "        \"ENSG00000227232\",\n",
    "        \"ENSG00000243485\",\n",
    "        \"ENSG00000237613\",\n",
    "        \"ENSG00000268020\",\n",
    "        \"ENSG00000186092\",\n",
    "    ],\n",
    "    \"Gene\": [\"DDX11L1\", \"WASH7P\", \"MIR1302-11\", \"FAM138A\", \"OR4G4P\", \"OR4F5\"],\n",
    "    \"GTEX-1117F\": [0.1082, 21.4, 0.1602, 0.05045, 0, 0],\n",
    "    \"GTEX-111CU\": [0.1158, 11.03, 0.06433, 0, 0, 0],\n",
    "    \"GTEX-111FC\": [0.02104, 16.75, 0.04674, 0.02945, 0, 0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455af7f-8647-448e-98eb-b01b554aa29e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9b1ec-e64e-465f-a3f5-74bc6331fb4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create and re-order column names\n",
    "df_gene = pd.DataFrame(\n",
    "    data, columns=[\"Gene\", \"EnsemblID\", \"GTEX-1117F\", \"GTEX-111FC\", \"GTEX-111CU\"]\n",
    ")\n",
    "df_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda77c89-f44b-4c49-8f42-4943dd11c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd675318-522c-49c6-975d-7a4dd1cedbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows and columns\n",
    "# (shape is an attribute of df)\n",
    "df_gene.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6886a2-1d33-4e6a-a937-c81f1b5eb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the column names (another attribute)\n",
    "df_gene.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07edf5-297d-48e5-938a-f38b84a75b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index (another attribute)\n",
    "df_gene.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417fd315-3824-49f7-84b1-57670fa9d275",
   "metadata": {},
   "source": [
    "Note that column names and index have their own types `Index` and `RangeIndex` - it is not a Python list (even though it looks like a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0627db-f2be-4e36-a63f-90aab9893d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new index (original dataframe is not modified)\n",
    "df_gene.set_index(\"EnsemblID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7b2e0-8cdb-42ea-95cd-3c0bb0b287e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new index in-place (mind the above caveat about the use of inplace)\n",
    "df_gene.set_index(\"EnsemblID\", inplace=True)\n",
    "df_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0da5ec-7fa6-48f0-a072-f9ec0c04b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the type of each column\n",
    "df_gene.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac6793-6ba0-4cfd-85c9-2945901d8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more info\n",
    "df_gene.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5112d-d15a-42ac-bd6c-4219683bc9ea",
   "metadata": {},
   "source": [
    "To transpose, we can use the numpy syntax `.T`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b29b21-81f3-4fd1-bc11-f43ca9781842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose v1\n",
    "df_gene.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832552c9-6772-49ff-bb5c-6ef82ef4f4b1",
   "metadata": {},
   "source": [
    "Or a more human readable syntax `.transpose()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a37fc-f9ec-401f-b004-3a035b8d7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose v2\n",
    "df_gene.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8732adf-8436-4b46-a1c3-64c6e358af82",
   "metadata": {},
   "source": [
    "Quick summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a470a-ea3d-4eea-80fc-dc6d1567b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e7395-4773-458d-aa14-9117d9a128aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de372347-0460-426e-9230-b9b1e272921b",
   "metadata": {},
   "source": [
    "To convert a dataframe to a numpy array, just use the `.values` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195e181-8ff3-4f59-a87b-24460ac54d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9abd69-6520-4dd6-bcc2-042becbc8da3",
   "metadata": {},
   "source": [
    "### Select columns: by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad3e0d-446b-48bf-b583-5ed10f2347df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single column (returns a Series)\n",
    "df_gene[\"Gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de735e-0eab-4235-b939-aedaa11b9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multicolumn (returns a DataFrame)\n",
    "df_gene[[\"Gene\", \"GTEX-1117F\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cbd054-f4e6-4051-99d7-efb5e77b1ff3",
   "metadata": {},
   "source": [
    "### Select columns: by condition\n",
    "\n",
    "Often you'll have to select (or filter out) columns based on a pattern: e.g., all those columns starting with, ending with, or containing something.\n",
    "\n",
    "For this, you can manipulate column names using methods from the built-in `str` Python module: for example, `str.startswith()`.\n",
    "\n",
    "To get access to these string methods on a DataFrame value or column name, you need to use the `.str.` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7552d2-d29a-4f8d-8d33-9649796d808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns starting with GTEX\n",
    "condition = df_gene.columns.str.startswith(\"GTEX\")\n",
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b053f-3b16-49f2-90b1-52486efb64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene[df_gene.columns[condition]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f3a6b-292b-4216-8490-821945b6706e",
   "metadata": {},
   "source": [
    "This `.str.` attribute is called \"accessor\" because it can access string methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbfc0e1-3c64-4606-8924-9f7d0848befb",
   "metadata": {},
   "source": [
    "### Select rows: by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78fa8aa-173e-4070-8390-c9b9afdb0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 1st row\n",
    "df_gene.loc[\"ENSG00000223972\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33ec1f-70dc-40b0-97f0-49cd4e472d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (attempt to) get the last row\n",
    "# df_gene.loc[-1]\n",
    "# won't work because Pandas will look for a row index label '-1'\n",
    "\n",
    "# revised version\n",
    "nrows = df_gene.shape[0]\n",
    "df_gene.loc[df_gene.index[nrows - 1]]  # output: Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23b6e2-2a89-42d4-a306-84becbc96386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.tail(1)  # output: DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19bd168-7c80-429f-ae14-07aedb74af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset multiple rows by using a list\n",
    "df_gene.loc[[\"ENSG00000223972\", \"ENSG00000243485\"]]  # output: dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd498a62-bc66-4be4-b58e-7933a476c0d0",
   "metadata": {},
   "source": [
    "### Select rows: by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffbf96-5b08-48e5-b9fc-484dc968e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = df_gene[\"GTEX-1117F\"] >= 5.\n",
    "df_gene.loc[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56fe82-83f5-4b0e-882d-2e0eca47c6a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_gene.query(\"`GTEX-1117F` >= 5\")  # protect the column name with `` (since it contains a -)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b05c89e-96cd-4bf3-ab5a-5f31f2933e88",
   "metadata": {},
   "source": [
    "### Select rows: by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9d730-03ce-489f-ae9a-0aedbeb9c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa1e46-0177-4b30-8143-8ad9f4914a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f67cb15-ddab-48a4-b7fd-dddf140985c2",
   "metadata": {},
   "source": [
    "### Select rows & columns\n",
    "\n",
    "You can use `.loc[]` and `.iloc[]` to select columns too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bd358-fb8f-4983-9531-1da865d04f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.loc[:, [\"GTEX-1117F\", \"GTEX-111CU\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8390333-a121-4330-9431-2c568b4e0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above but using iloc\n",
    "df_gene.iloc[:, [1, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c124d5e-c9e2-4068-b4ac-4949a8c779ff",
   "metadata": {},
   "source": [
    "You can select contiguous ranges as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0570fa-44b8-4ed9-9eb3-31975820fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.loc[:, \"GTEX-1117F\":\"GTEX-111CU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45fb29d-022e-4d2c-a3c4-285fc905d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.iloc[:, range(1, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961228b-f52a-417f-b6f7-18d584a74de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.loc[\"ENSG00000237613\", \"GTEX-1117F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129b0fc-b9e8-4691-9eac-647eadb10e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.iloc[3, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe079f-f1c9-4097-b52c-fed101217ed3",
   "metadata": {},
   "source": [
    "Hint: whenever possible, use the actual column names when you select/subset the data (so, prefer `.loc[]`). Using absolute indexes can lead to issues if the order of rows or columns is changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439bfe9-1165-41b6-863b-9ac8e41aa2f0",
   "metadata": {},
   "source": [
    "### Multiple conditions\n",
    "\n",
    "Multiple conditions can be combined using the same rules that apply to Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1305d3b-0f38-41ef-8902-96292912d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (df_gene[\"GTEX-1117F\"] > 5.) | (df_gene[\"GTEX-111FC\"] > 0.03)\n",
    "df_gene.loc[cond]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe1a19-22ca-4e19-b984-d81d2505a298",
   "metadata": {},
   "source": [
    "### Sort rows\n",
    "\n",
    "You can apply the `.sort_values()` method on a dataframe to sort by a column, optionally selecting the sort order with the boolean `ascending` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca39c47-7b57-4452-916b-f691854e430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort rows (genes) by decreasing expression in sample GTEX-1117F\n",
    "df_gene.sort_values(by=\"GTEX-1117F\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba85103-4cbe-43cf-bbad-7252ed48e887",
   "metadata": {},
   "source": [
    "A column is a Series, so as we did before we can apply `.sort_values()` to any column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa379fa1-b4de-48f5-9a7d-f15f7d368844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene[\"GTEX-1117F\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce3b0e6-fc5e-4f14-bfab-d7a4e375d494",
   "metadata": {},
   "source": [
    "### Add/remove/modify columns\n",
    "\n",
    "You can add and remove columns as part of your initial data cleaning phase. Modifying columns is usually part of the feature engineering, where you create new, more effective features (columns) for downstream analysis (e.g. machine learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d12d13-a228-4102-b6d6-fd8273882791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df_gene[\"dummy_col\"] = np.random.normal(loc=10, size=df_gene.shape[0])\n",
    "df_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb2ded-311d-4d8c-96a8-a783a7f6a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns: method 1\n",
    "df_gene.drop([\"dummy_col\", \"GTEX-111CU\"], axis=1)  # axis=1 -> operate on columns; axis=0 -> rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6676f64-b601-4455-a626-9218506f2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns: method 2\n",
    "df_gene = df_gene.drop(columns=[\"dummy_col\", \"GTEX-111CU\"])\n",
    "df_gene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79903584-3588-49a2-bcfb-540869555152",
   "metadata": {},
   "source": [
    "We can assign and modify columns with the `.assign()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4d4b5-ea11-43e9-a8a1-3d6b657667a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.assign(\n",
    "    delta=df_gene[\"GTEX-1117F\"] - df_gene[\"GTEX-111FC\"],\n",
    "    logdelta=np.log2(1 + df_gene[\"GTEX-1117F\"] - df_gene[\"GTEX-111FC\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9bca6-b73b-40d3-be1f-f31ed290081f",
   "metadata": {},
   "source": [
    "If you are familiar with R's `dplyr`, at this point you may be wondering: in the above code, wouldn't be much easier to write something like  `logdelta = np.log2(1 + geneExp_df[\"delta\"]`?\n",
    "\n",
    "If we tried, we would get an error: that's because we are accessing the newly created column in the wrong way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8210ce6f-a4e0-435a-9de0-209ffff2a7ec",
   "metadata": {},
   "source": [
    "To explain the process, we need to use a **lambda function** (more on this shortly).\n",
    "\n",
    "Let's see how lambda functions work on a simple dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b26ab7-bf11-4bb3-b363-7a1b9a7d6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = pd.DataFrame({\"a\": [10, 20, 30], \"b\": [20, 30, 40]})\n",
    "toy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a28c4-85bd-4bbe-b9c0-01679f303c72",
   "metadata": {},
   "source": [
    "If I wanted to apply a function to the `a` column (say, the square), the usual way would involve the creation of the function, which I would apply to the column with the pandas `.apply()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a2b71-c9df-42be-954b-f6651d136aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sq(x):\n",
    "    return x**2\n",
    "\n",
    "\n",
    "toy[\"a_sq\"] = toy[\"a\"].apply(my_sq)\n",
    "toy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bcc4e9-9b04-4a57-bb33-8c67713fce44",
   "metadata": {},
   "source": [
    "Seems a lot of work for such a simple function. So I'm going to use a lambda function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a3a22-1861-46e3-b27d-f659ce1a0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy[\"a_sq_lambda\"] = toy[\"a\"].apply(lambda x: x**2)\n",
    "toy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4e598-4781-4d4a-a18b-391bfb914958",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "A **lambda function** is a function simple enough that we don't even need to give it a name - that's why they are also called \"anonymous function\".\n",
    "\n",
    "Typical use case is for one-liners, like the one above.\n",
    "\n",
    "The `x` in `lambda x` is each individual value of `toy[\"a\"]`, which is passed to the anonymous function. The result is automatically returned (no need to `return` anything).\n",
    "\n",
    "R also has anonymous functions, often used in combination with `apply()`, `sapply()`, etc.: consider for example `sapply(toy$a, function(x) x**2)`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ecffc-17f1-49e2-8725-5152664d2eef",
   "metadata": {},
   "source": [
    "Now we can rewrite the `.assign()` statement with a lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63992ec9-ff2f-4a95-a1d6-7a5e79580db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.assign(\n",
    "    delta=df_gene[\"GTEX-1117F\"] - df_gene[\"GTEX-111FC\"],\n",
    "    logdelta=lambda df_: np.log2(1 + df_[\"delta\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0762415-a324-4da0-8c33-e44e80dce2c6",
   "metadata": {},
   "source": [
    "Columns are easily renamed with the `.rename()` method, accepting a dictionary in the form `{'old_name': 'new_name'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fef97-8e53-4d50-bb46-3892e720c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.rename(columns={'GTEX-1117F': 'Sample1', 'GTEX-111FC': 'Sample2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f3573-96bb-479e-83c0-9e524df9a66a",
   "metadata": {},
   "source": [
    "### Reading from files\n",
    "\n",
    "Pandas has convenient `read_<format>` methods to read data in different formats (CSV, TSV, Excel, JSON, pickle, etc.).\n",
    "\n",
    "Let's load a small toy dataset about how mouse weight responded to a particular treatment. This data contains 4 columns: \n",
    "\n",
    "- `Mouse`, the mouse label/number\n",
    "- `Treated`, whether or not it was treated\n",
    "- `Sex`\n",
    "- `Weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d64f1-4d25-4874-96f3-ae59bea0a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATADIR / \"mouse_weight_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c6603-af16-4355-987f-23987126dc2b",
   "metadata": {},
   "source": [
    "By default, the resulting dataframe is indexed from 0 to the number of rows. We are not quite happy with this because we would like to use the Mouse ID instead. Let's fix this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f1a8d-6a34-4968-87ee-b62e000e293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"Mouse\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8ba7c-0afa-4fe5-bb38-f2d94cd35407",
   "metadata": {},
   "source": [
    "Want to go back? Just use `reset_index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c4835-751e-47e3-9eab-504d8c805188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375059f3-35a9-4669-abff-a90dd7c80575",
   "metadata": {},
   "source": [
    "You can set the correct index straight from `pd.read_csv()`, by setting the argument `index_col` to the column name that you want to use as index!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd92e32-d460-47d4-b6ff-504c95b3b67a",
   "metadata": {},
   "source": [
    "### Exercise: Statistical testing revisited\n",
    "\n",
    "1. (Re)load the `mouse_weight_data.csv` from the `data` folder using the column \"Mouse\" as index\n",
    "2. Extract the weights of the treated and the untreated mice (hint: the column Treated is boolean: use it to select groups; in Pandas conditions, use `~` to negate)\n",
    "3. Calculate the mean weight per group and print them\n",
    "4. Test for statistical significance: there are two group involved, so you'll need a two-sample t-test (`ttest_ind()` from scipy `stats`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a8f1d7-4135-4533-b6cf-4e2dd85523a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_df = pd.read_csv(DATADIR / \"mouse_weight_data.csv\", index_col=\"Mouse\")\n",
    "mouse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a1611-836e-45e8-827b-8bb902c59828",
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_weights = mouse_df[mouse_df[\"Treated\"]][\"Weight\"]\n",
    "untreated_weights = mouse_df[~mouse_df[\"Treated\"]][\"Weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c8344-4df2-4c36-bd80-b506e78c249f",
   "metadata": {},
   "source": [
    "We start by checking if the mean weight is different between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c89aa-7007-4404-9b0d-de6b7c19bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_mean = treated_weights.mean()\n",
    "untreated_mean = untreated_weights.mean()\n",
    "print(f\"Treated mean weight: {treated_mean:0.0f}g\\nUntreated mean weight: {untreated_mean:0.0f}g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775729f5-4f6b-4dde-a4af-4019a9f34410",
   "metadata": {},
   "source": [
    "It is slightly different, but is this due to randomness/noise in the data?\n",
    "\n",
    "Let's test for statistical significance: since there are two groups involved, we have to use a two-sample t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5fe97-7028-452d-9c69-bef66403663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(treated_weights, untreated_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b4338-426e-46c0-ae66-90c1b9ebe7fb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Missing values (DataFrames)\n",
    "\n",
    "What we saw earlier on Pandas Series also applies to DataFrames.\n",
    "\n",
    "On DataFrames, it may be more practical to use the `.info()` or the `.count()` methods to get an overview of the non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc6ba7-fba8-4c97-9a58-c54f3c662f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola = pd.read_csv(DATADIR / \"country_timeseries.csv\")\n",
    "ebola.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b3f8be-c772-4122-af35-a2b932ee596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5faa543-7b66-4f4d-8efc-dc29dd41edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the no. of non-missing values\n",
    "ebola.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7753692-8398-4e7e-86bf-d4abc7351e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive the total no. of missing values\n",
    "np.count_nonzero(ebola.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399b6b5-fdfa-4955-8e5f-eadc1764a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for an individual column\n",
    "ebola[\"Cases_Guinea\"].value_counts(dropna=False)  # also: ebola[\"Cases_Guinea\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2d454-e308-493a-8eee-130f2f2f0ff7",
   "metadata": {},
   "source": [
    "### Handle missing values\n",
    "\n",
    "You can use the same methods that work on Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2ae0f-a62f-41ec-9e88-af1d3d2cc05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf148ba-fe16-4d97-958e-460026e8c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only complete cases\n",
    "ebola.dropna().head()  # only 1 row!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc972f-69ba-4af0-ad05-6a9e3b1c7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use axis=1 to remove columns with (any) missing values\n",
    "ebola.dropna(axis=1).head()  # 2 columns left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988dd4d2-d414-4591-aa6f-92c7cd9a7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.fillna(0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac84a5-9574-4ac9-a9f2-64ad33379d19",
   "metadata": {},
   "source": [
    "Here is the DataFrame edition of the rules of thumb we previously saw for Series:\n",
    "\n",
    "- You should **drop rows** (samples) when a lot of data is missing;\n",
    "- You should **drop columns** (features) if many rows are missing that particular feature;\n",
    "- You should **fill with the same value** if you know that NaN is just a placeholder (e.g., for 0);\n",
    "- You should **fill with interpolated or estimated value** if there is a reasonable assumption to do that!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7eff22-88b5-4e09-9e9f-fef6698bdb04",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Grouped operations\n",
    "\n",
    "Pandas has the `.groupby()` method that allows you to compute grouped (or aggregated) calculations. For example, in our Mouse dataset:\n",
    "\n",
    "- what is the average weight by sex?\n",
    "- what is the average weight by sex, stratified by treatment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1027787a-15cd-480e-bf44-9470ccd8fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_df.groupby(\"Sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136f910-2634-40ad-ab0b-bbe731a8d2fd",
   "metadata": {},
   "source": [
    "`.groupby()` alone does nothing visible: it *prepares* the data for downstream computations. \n",
    "\n",
    "In other words, it creates a \"lazy\" groupby object waiting to be evaluated by an *aggregate method* call, such as `.sum()`, `.mean()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd8a25-b498-42c8-addd-f76ff774842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_df.groupby(\"Sex\")[\"Weight\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e8cf0-dace-4f5f-b6aa-1b1c8ac0cd20",
   "metadata": {},
   "source": [
    "If you prefer, you can assign the grouped dataframe to its own variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50f5fe-1828-45ab-80d1-4910570dcc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = mouse_df.groupby(\"Sex\")\n",
    "grouped_df[\"Weight\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cdf3c-ed09-4ee7-b642-2adc6c963783",
   "metadata": {},
   "source": [
    "It is easy to group by more than one variable: for example, let's compute the average `Weight` broken down by `Sex` and `Treated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8388a11-a28f-437d-adfc-ac1e78ccbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_var_df = mouse_df.groupby([\"Sex\", \"Treated\"])[\"Weight\"].mean()\n",
    "multi_var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca4593-8d23-4331-91f0-73d3b15ed2ef",
   "metadata": {},
   "source": [
    "**Hint:** you can use `( )` to wrap long statements, writing each method on its own line (\"method chaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d4a65-a81f-4053-8516-b6d2c728d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_var_df = (\n",
    "    mouse_df\n",
    "    .groupby([\"Sex\", \"Treated\"])\n",
    "    [\"Weight\"]\n",
    "    .mean()\n",
    ")\n",
    "multi_var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa55f2-6fc1-450f-8446-f28d5a48a8cf",
   "metadata": {},
   "source": [
    "Notice the hierarchical structure of the row indexes. If you prefer, you can \"flatten\" it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56bb480-3562-4222-b51f-9585f5e3ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_df = multi_var_df.reset_index()\n",
    "flat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465bfeb-bf1c-493b-b3bb-cbbec52b5ae2",
   "metadata": {},
   "source": [
    "On a grouped dataframe you can also apply custom functions with `.apply()`. Here's an example displaying the first (or last) `Weight` for each unique `Sex` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04836a52-f2f7-40ab-981e-38c4632fc8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_df.groupby(\"Sex\").apply(lambda df: df.Weight.iloc[0], include_groups=False)\n",
    "# include_groups=False is to exclude the grouping columns from the operation\n",
    "# it will become the default value in future versions of Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab181778-91d0-4a25-a116-c7e24b2c3cf3",
   "metadata": {},
   "source": [
    "Another `groupby()` method worth mentioning is `.agg()`, which lets you run a bunch of different functions on your DataFrame simultaneously. For example, we can generate a simple statistical summary of the dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aea341-a429-475c-9a28-f62085f3e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_df.groupby(\"Treated\").Weight.agg([\"min\", \"max\", \"mean\", \"median\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2955038e-8fab-43fa-bb74-5fc1070b0281",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "The file \"neuroblastoma.tsv\", in the `data` folder, contains a few clinical parameters and the expression of 3 genes (MYCN, ALK, and TP53) for 20 neuroblastoma patients, randomly selected from a larger set.\n",
    "\n",
    "Read the file with `pd.read_csv()`, setting the appropriate separator through the argument `sep`, and save it to `nb_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7098508-82fd-4e48-8d8d-cfb378a73df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_df = pd.read_csv(DATADIR / \"neuroblastoma.tsv\", sep=\"\\t\")\n",
    "nb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f6f14-8ea8-42c5-868f-b999e01e8870",
   "metadata": {},
   "source": [
    "1. Create a DataFrame `avg_surv` containing the average survival time (`os_years`) broken down by the neuroblastoma INSS staging `inss_stage`. What stage is associated with the worst prognosis, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2549d-a8cd-4ef6-9016-c2f050731863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c32e23-180a-4dca-b459-1c6554fc4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_surv = nb_df.groupby(\"inss_stage\")[\"os_years\"].mean().sort_values(ascending=True)\n",
    "avg_surv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa8f28-5640-4bdb-8bef-595eb3a7b0a8",
   "metadata": {},
   "source": [
    "2. What are the minimum and maximum survival times for each `age_group`? (age at diagnosis) Create a DataFrame whose index is the age group category from the dataset and whose values are the min and max values thereof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5558a-be39-4040-b56d-1481aec9f51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21105e25-6c22-4d54-bcab-f6c65e8340bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_extremes = nb_df.groupby(\"age_group\")[\"os_years\"].agg([\"min\", \"max\"])\n",
    "surv_extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e41859-e1d5-49e0-955b-42429e471bd6",
   "metadata": {},
   "source": [
    "3. Create a `Series` whose index is the `high_risk` status and whose values are the average expression value of TP53 for each value of `high_risk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828beb7-3d0f-41c9-83f2-8fd9ebfccc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc439c-d23c-44a0-a8e4-aa7f250f4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_mean_expr = nb_df.groupby(\"high_risk\")[\"TP53\"].mean()\n",
    "hr_mean_expr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cefa1165-6862-4e2b-8834-f53fc809f8a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Combining data\n",
    "\n",
    "Combining data is another part of your typical data analysis workflow. For example, you have sample IDs and clinical data in one file, and gene expression value for those samples in another file, and you want to combine those two files in the most robust way.\n",
    "\n",
    "Merging, or joining, data is more elaborate than a simple concatenation: it resembles a database join, where you combine one or more tables based on common data values.\n",
    "\n",
    "Pandas has a `.merge()` method to perform this kind of operation.\n",
    "\n",
    "The syntax is `left.merge(right)`, meaning that a `left` dataframe will be merged with the `right` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08eac3-60b7-4bf0-be2e-4457d70107b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = pd.read_csv(DATADIR / \"survey_site.csv\")\n",
    "visited = pd.read_csv(DATADIR / \"survey_visited.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c9933-3e82-4ef4-bbf1-bd87978f992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dd537-a10c-4ed3-bc6c-f8c48aa014e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e2500-108e-4fac-bcc6-b3884dde4a61",
   "metadata": {},
   "source": [
    "Let's merge `sites` (\"left\") and `visited` (\"right\"), using the common column `site`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2251c6-617d-40a1-9e07-e964718a5a3e",
   "metadata": {},
   "source": [
    "### One-to-one merge\n",
    "\n",
    "This kind of merge works when there are no duplicate values in the joining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cbf4d-1a7d-402d-8ca3-6d916ba26c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites.merge(visited, left_on=\"site\", right_on=\"site\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcfdc58-a4ae-436a-bab0-00bf90513383",
   "metadata": {},
   "source": [
    "See how the resulting dataframe has the first columns from the \"left\" dataframe.\n",
    "\n",
    "The optional argument `how` determines the type of join:\n",
    "\n",
    "- `how=\"inner\"` (default), use intersection of keys from both dataframes\n",
    "- `how=\"outer\"`, use union of keys from both dataframes\n",
    "- `how=\"left\"` / `how=\"right\"`, use only keys from left (right) dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c367f7d-a164-4194-904c-ccf8a5c214d6",
   "metadata": {},
   "source": [
    "### Many-to-one\n",
    "\n",
    "In case the joining column contains duplicates, you would obtain a \"many-to-one\" merge, where all the left dataframe info are matched to the right dataframe and replicated as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d57a55-37e6-4842-a92e-4e70160ae58a",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "You have to merge clinical information (stored in the file `nb_clinical.txt`) with gene expression (provided in the file `nb_expr.txt`) into a single dataframe.\n",
    "\n",
    "Start by reading the two files into dataframes, figuring out the file format and the separator.\n",
    "\n",
    "Have a look at the data and check the sizes.\n",
    "\n",
    "Merge the two dataframes. Clean up the merged dataframe be dropping redundant columns, if any.\n",
    "\n",
    "Finally, impute missing values to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e000dd-d99c-4fdd-a63f-9ea131451c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical = pd.read_csv(DATADIR / \"nb_clinical.txt\")\n",
    "df_expr = pd.read_csv(DATADIR / \"nb_expr.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25ce8f-acdf-472e-a181-c7339bdcadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf98207-cf5a-4227-8b6c-12b116a45361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aeaddc-e56c-46fe-9a30-5c2120662eba",
   "metadata": {},
   "source": [
    "We don't have clinical information for all of the samples (real-world scenario). We should perform an inner join to keep only common samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3b557-400e-4db1-93b0-78814cdc334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_clinical.merge(df_expr, how=\"inner\", left_on=\"sample_id\", right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c66c31-3e26-4078-a68e-46b5a3da760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f46d3-bf18-43a3-9194-26addefe83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop(\"ID\", axis=1)\n",
    "df_merged.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac0174-d678-48a0-bf79-1787185b9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate method\n",
    "df_clinical = pd.read_csv(DATADIR / \"nb_clinical.txt\", index_col=\"sample_id\")\n",
    "df_expr = pd.read_csv(DATADIR / \"nb_expr.txt\", sep=\"\\t\", index_col=\"ID\")\n",
    "df_merged = df_clinical.merge(df_expr, how=\"inner\", left_index=True, right_index=True)\n",
    "df_merged.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e4ad95-992a-4ed4-a20f-7e6cb5b53e30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Breast Cancer Detection Data Set\n",
    "\n",
    "source: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "The data comprises features from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image in the 3-dimensional space. For now, there is no need to fully understand where the variables come from or their units: the focus here is to explore what we can do with Pandas and understand how easy it is to apply these tools to any kind of data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f97ec-6f1a-4fc5-a10f-bb228b4eda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re)import libraries in case you start from scratch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# compose paths and filenames using pathlib, which is operating system-agnostic\n",
    "# then load the data using Pandas\n",
    "DATADIR = Path(\"data\")\n",
    "DATAFILE = DATADIR / \"breast_cancer_diagnostic_data.csv\"\n",
    "bc_data = pd.read_csv(DATAFILE)\n",
    "bc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f1a77-9817-4c4b-9e30-b99bfc6fcdca",
   "metadata": {},
   "source": [
    "Other parameters can be used inside `read_csv()` to deal with different types of data: for example, different separators, unwanted rows or columns, variable names, and other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab66f10-4e20-4212-87bc-ce0e2af240d7",
   "metadata": {},
   "source": [
    "```python\n",
    "# to skip (100) rows\n",
    "pd.read_csv(DATAFILE, skiprows=100)\n",
    "\n",
    "# if the dataset has no header\n",
    "pd.read_csv(DATAFILE, header=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e43c64-2c58-4234-9cdd-d1562ecf7202",
   "metadata": {},
   "source": [
    "Our data set contains 569 samples (patients), categorical data (diagnosis result) and numerical data (31 attributes concerning the tumor shape and size and the id of each patient). We are now ready to start exploring and manipulating the data as intended. The script below shows a few examples of simple operations that can be applied with just a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691302e-ee87-4710-8a49-880e5cf2f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dimensions\n",
    "bc_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78527d8-d7a5-4553-ab31-a5874cfe73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the header\n",
    "bc_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5eb7d-c73d-4b06-851f-025f8cf3f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the index\n",
    "bc_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f1a2c-ac42-4346-872c-f573cd54c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the last n rows\n",
    "bc_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af944e50-de7e-4388-88e9-8bd4e3792dc5",
   "metadata": {},
   "source": [
    "## Review Exercise\n",
    "\n",
    "Index this dataframe by sample ID, instead of the default indexing. You can do that in two ways: by using `set_index()` on the dataframe, or by re-reading it from file specifying which column should be used as the index. Then, use indexing/slicing methods to perform the operations in the below cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bfd3d3-689d-4391-86f1-536430b58253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d02291-7daa-422b-8b8f-c7abe0287cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your preferred method to index the df by sample ID\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9a9d6-ae83-4763-9881-aef4bca66842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the contents of the column \"area_mean\"\n",
    "# (output: list/array containing column values for all rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6534e6b-6cb9-41f1-bb58-2c10f373502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset of the data with the columns \"area_mean\", \"perimeter_mean\", \"texture_mean\"\n",
    "# (output: a dataframe containing selected columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc809e3-3a8a-4f75-92d3-aab7d4dab49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the information of a given patient by row index, i.e. select row 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03210734-efe6-4e85-a071-92c432fe4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a slice of the table by row index\n",
    "# (output: a subtable containing row indexes from 9 (incl.) to 90 (incl.))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ed270-652e-4f06-97c2-9cfc2b69afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns from the table without overwriting the original data\n",
    "# (output: table without column \"compactness_mean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6591b-13ee-4d4b-9d42-b782e8ac0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select slices of lines and columns simultaneously by their index:\n",
    "# - select row indexes 50 to 70 (incl., excl.)\n",
    "# - select column indexes 5 to 10 (incl., excl.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b98d3a-6341-4cd1-a3d4-bc3b209f5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missingness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4df69-1e30-4e82-88d2-35e91a4f8084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns containing any number of missing values,\n",
    "# saving the result to a new dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4548e5-a392-488c-b942-67f3126b12c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe named \"bc_data_subset\" containing all the rows and only the first 7 columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6985c8-e143-44ed-b589-c4cb8ba4c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns with better/shorter names,\n",
    "# i.e., without the _mean suffix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ce4ff-6c07-441f-a105-7fb0b5bd81f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f33809-1f7e-4df0-8e78-5dcba927806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select patients that showed tumors with an area superior to 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419b118-904b-41e0-a02b-d487fb021364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4fe91-d24d-403d-975b-c453b3df4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# of those tumors with an area superior to 1000, how many had a perimeter superior to 180?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846fef7-fca9-4b71-8e86-dacb2a3acf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a1a36-f9e0-421e-8cc2-bb64354449f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the mean tumor area of patients for each diagnosis (Benign/Malignant)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbf927-f88a-4052-b634-47e64cf98b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f4a595-d6b9-47c4-a91b-73991cd7fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the median?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5c745-dfa8-47fa-b9df-b69292f20a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2d1b3-350e-4353-aac7-dbae3b342024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the median value of all parameters for each level of diagnosis?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb589f03-1c74-40a6-81ee-0563b37c4988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "692d93cb-77b0-46a9-b6c1-055345a8e059",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Export & import data\n",
    "\n",
    "It is very common to export (save) data while we process them - either at the end of the processing workflow, or as intermediate steps. It is perfectly fine to save intermediate files! Especially while you are setting up and fine-tuning the preprocessing steps.\n",
    "\n",
    "In any case, the data sets you save can be used as inputs for the downstream analysis (e.g. statistical modeling, machine learning, visualization).\n",
    "\n",
    "We did a bit of preprocessing on our BC data: so, we have now reached a quintessential \"data export\" moment.\n",
    "\n",
    "Pandas offers convenient methods to export data in different formats: you apply these methods directly on DataFrames (or Series). They are named after the output format, e.g. `.to_<format>()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e4a66-6986-47dd-be06-3bb3f51633d4",
   "metadata": {},
   "source": [
    "### Pickle\n",
    "\n",
    "Pickle is Python's serialized format. I would say it is the counterpart of R's RDS format (e.g. `saveRDS()`).\n",
    "\n",
    "Pickle files are binary: if you open them in a text editor, you'll see a lot of weird characters. This format is optimized for Python and disk storage space.\n",
    "\n",
    "Common file extension for Pickles are `.pkl` or `.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b38cb-8d17-44a3-a8d7-00b16d09601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed dataframe to pickle\n",
    "bc_data_subset.to_pickle(DATADIR / \"bc_new_table.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26b708-15b2-4b15-b4fe-f79c72289cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read back to a dataframe\n",
    "bc_pickle = pd.read_pickle(DATADIR / \"bc_new_table.pickle\")\n",
    "bc_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f767b6-ef5b-4033-8597-5e8c09cbef07",
   "metadata": {},
   "source": [
    "### CSV/TSV\n",
    "\n",
    "Comma-separated values, or tab-separated values, are textual file formats. They are the most flexible storage type: any text editor or program can open this kind of files. You can share them with everyone.\n",
    "\n",
    "On the downside, CSVs are usually slower and bigger than other binary formats.\n",
    "\n",
    "Pandas Series and DataFrames have the `.to_csv()` method to write delimiter-separated values: it defaults to comma as the separator, but you can change this with the `sep` argument (e.g. `sep=\"\\t\"` for TSVs).\n",
    "\n",
    "By default, the `.index` of a DataFrame is written to the CSV. If the DataFrame has a *named index*, like our `bc_data_subset` here, then no problem: the index will be saved as the first column, with its name. If, however, the DataFrame has an index without a name, then also the output file will have the first column without a name. This may create problems when reading the CSV back to Pandas. To overcome this, you have two options:\n",
    "\n",
    "- you set `index=False` when you save the file\n",
    "- you save the file with `index=True` (default), and you read it back using `pd.read_csv(..., index_col=0)` to tell Pandas that the first column holds the index.\n",
    "\n",
    "For `bc_data_subset`, we'll just set the separator to tab and then use the other default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bddd7f-c191-4d4c-98e7-e90f0c7857b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to TSV\n",
    "bc_data_subset.to_csv(DATADIR / \"bc_new_table.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5cf4e0-7994-493e-a331-0fa2f7b7248b",
   "metadata": {},
   "source": [
    "### Excel\n",
    "\n",
    "Let's face it: Excel has a bad reputation in the data science community. Some of its obvious limitations include potential issues due to color-coding information, weird datetime conversions, and so on. \n",
    "\n",
    "Still, Excel is probably still the most commonly used file format: so, we are not here to blame it but to learn how to export to or import from Excel format, in case you have to collaborate with people who use it - while you are learning a cool alternative tool for data analytics with Pandas and Python :)\n",
    "\n",
    "Before reading and saving Excel files with Pandas, you need to install the `openpyxl` library. Copy-paste the following in the cell code below and run it:\n",
    "\n",
    "```\n",
    "!conda install -y -c conda-forge openpyxl\n",
    "```\n",
    "\n",
    "If you are a Windows user, replace `conda` with `conda.exe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe272fd-da0e-4130-bb23-9400e9c19a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd923fe-5bf8-436f-ac12-9876689ae2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data_subset.to_excel(DATADIR / \"bc_new_table.xlsx\", sheet_name=\"BC data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf9201-60e7-439e-83a3-251289e2103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_excel = pd.read_excel(DATADIR / \"bc_new_table.xlsx\", sheet_name=\"BC data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ebe60-197f-4548-891f-b9bb325225ed",
   "metadata": {},
   "source": [
    "### Feather\n",
    "\n",
    "[Feather](https://arrow.apache.org/docs/python/feather.html) is another binary format, similar to Pickle. But it has the advantage that it can be read by other languages, like R, and it is faster than CSV. Feather is part of the Apache Arrow project. \n",
    "\n",
    "Again, you'll probably need to install a dependency:\n",
    "\n",
    "```\n",
    "!conda install -y -c conda-forge pyarrow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509905ef-174b-466e-9f2a-170b67adb752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367692de-25f0-4a8b-a8e1-619d6443d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data_subset.to_feather(DATADIR / \"bc_new_table.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee4d14-ac8e-49b9-8e09-b6a66e17332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_feather = pd.read_feather(DATADIR / \"bc_new_table.feather\")\n",
    "bc_feather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307f82e-dda8-408c-8921-46bffbe189de",
   "metadata": {},
   "source": [
    "### Dictionary\n",
    "\n",
    "You can also convert a Series or DataFrame into a Python dictionary. This is convenient if you have to work on the data with Python, but outside Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53752e6-4a5c-41ba-8aff-aa056edb0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert just the first rows\n",
    "bc_dict = bc_data_subset.head().to_dict()\n",
    "print(bc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389601d0-ed62-4bd3-b21d-087c01265699",
   "metadata": {},
   "source": [
    "Printing a raw dictionary is quite ugly, isn't it? \n",
    "\n",
    "What better opportunity to showcase Python's \"pretty print\" function, from the library `pprint`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b6b92-5383-4403-b39b-680839bef7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(bc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c5fb9-6732-4074-a54f-8ecde7a82d50",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Credits\n",
    "\n",
    "Partially abridged from great work by Paulo Caldas https://github.com/paulocaldas, Samraat Pawar (MIT license), Center for Computational Biomedicine (Harvard Medical School), and others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
